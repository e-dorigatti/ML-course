{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>html, body{overflow-y: visible !important} .output_subarea{font-size:100%; line-height:1.0; overflow: visible;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preamble import *\n",
    "#HTML('''<style>html, body{overflow-y: visible !important} .CodeMirror{min-width:100% !important;} .rise-enabled .CodeMirror, .rise-enabled .output_subarea{font-size:100%; line-height:1.0; overflow: visible;} .output_subarea pre{width:100%}</style>''') # For slides\n",
    "HTML('''<style>html, body{overflow-y: visible !important} .output_subarea{font-size:100%; line-height:1.0; overflow: visible;}</style>''') # For slides\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "- Introduction and Motivation\n",
    "- Artificial Neuron\n",
    "- Gradient Descent\n",
    "- Backpropagation\n",
    "- Perceptron\n",
    "- Multilayered Perceptron\n",
    "- MLP Classification\n",
    "\n",
    "- Convolutional Neural Networks\n",
    "- **Recurrent Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential data\n",
    "- So far: Independent and Identically Distributed\n",
    "- Similar to the image data that had spatial correlation sequential data has dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - Data points have dependencies on previous datapoints\n",
    "    - Example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential data\n",
    "- Measurements of processes in time\n",
    "\n",
    "#### Example:\n",
    "- Working of the human hearth:\n",
    "![ECG](images/rnn/ecg01.png)\n",
    "\n",
    "#### Should take between .06 - .1s\n",
    "- Any longer may indicate abnormality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Sample of data sequence\n",
    "\n",
    "![ECG2](images/rnn/ecg02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Feature detector for the Q, S, R\n",
    "\n",
    "- Can we use a Conv net?\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Windowing\n",
    "- Window size?\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-01.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Location #2\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-02.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Faster sequence\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-03.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Location #3\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-04.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Sequential processing\n",
    "- Step 1\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-05.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Step 2\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-06.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Step 3\n",
    "\n",
    "![Image of CNN seq](images/rnn/ecg03-rnn-07.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feature detector for the Q, and S, and R\n",
    "- Remember the the point of Q\n",
    "- Remember the point of S\n",
    "- Remember the point of R\n",
    "- Count the distance from Q to S to R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential Data\n",
    "\n",
    "- Dependencies between the datapoints\n",
    "    - Example:\n",
    "        - Words in a sentence.\n",
    "        - Sentences in a paragraph.\n",
    "\n",
    "- Understanding text with a CNN is difficult\n",
    "    - The CNN needs to have feature detectors for all combinations of words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Auto regressive models\n",
    "Simple prediction model based on previous datapoints\n",
    "![Auto Regressive](images/rnn/autoreg01.png)\n",
    "\n",
    "$$x_t = w_0 x_{t-1} + w_1 x_t-2 + w_2$$\n",
    "$$x_t = G_\\theta(x_{t-1}, x_{t-2}, ...)$$\n",
    "\n",
    "- Fixed size input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- no parameter reuse\n",
    "- input size dimensions\n",
    "\n",
    "- Furthermore, we would like to deal with variable lenght sequences\n",
    "\n",
    "- Evenmore, we would like the output to be variable lenght \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). \n",
    "\n",
    "Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Recurrent Neural Network\n",
    "- Ideally, the model sees each input only once\n",
    "- Has a memory\n",
    "- Can map correlations over time\n",
    "\n",
    "![RNN](images\\rnn\\rnn01.png)\n",
    "\n",
    "$$h_t= W \\phi ( h_{t-1}) + U x_t$$\n",
    "$$y_t= V \\phi (h_t)$$\n",
    "- Turing complete model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, RNNs essentially describe programs. In fact, it is known that RNNs are Turing-Complete in the sense that they can to simulate arbitrary programs (with proper weights).   \n",
    "\n",
    "\n",
    "RNN computation. So how do these things work? At the core, RNNs have a deceptively simple API: They accept an input vector x and give you an output vector y. However, crucially this output vector’s contents are influenced not only by the input you just fed in, but also on the entire history of inputs you’ve fed in in the past. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Delay edge\n",
    "\n",
    "![RNN 02](images/rnn/rnn02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Diagram unrolled\n",
    "![RNN 02](images/rnn/rnn03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Network Model\n",
    "\n",
    "![RNN 02](images/rnn/vanilla-rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $a^{(t)}=b+Wh^{(t-1)}+Ux^{(t)}$\n",
    "- $h^{(t)}=\\tanh(a^{(t)})$\n",
    "- $o^{(t)}=C+Vh^{(t)}$\n",
    "- $\\hat{y}^{(t)}=softmax(o^{(t)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Cells unrolled\n",
    "![RNN](images/rnn/vanilla-rnn-cell-unrolled-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![RNN](images/rnn/vanilla-rnn-cell-unrolled-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What can we do with a RNN?\n",
    "\n",
    "\n",
    "1. Define tasks \n",
    "    seq 2 seq\n",
    "    seq classification\n",
    "    data point to sequence\n",
    "\n",
    "![RNN applications](images/rnn/rnn-app-0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![RNN applications](images/rnn/rnn-app-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![RNN applications](images/rnn/rnn-app-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![RNN applications](images/rnn/rnn-app-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "#### Backpropagation\n",
    "\n",
    "### Sequence to Sequence\n",
    "\n",
    "#### Model computation unrolled\n",
    "#### Apply Backpropagation\n",
    "- Backpropagation through time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/rnn/rnn-unrolled-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/rnn/rnn-unrolled-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/rnn/rnn-unrolled-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Backpropagation through time\n",
    "\n",
    "$$ L = \\sum_t L_t$$\n",
    "$$\\frac{\\partial L}{\\partial L_t}=1$$\n",
    "\n",
    "$$\\nabla_{O_t} L = \\frac{\\partial L}{\\partial O_t} = \\frac{\\partial L}{\\partial L_t}\\frac{\\partial L_t}{\\partial O_t} =  crossentropy (\\hat{y}, {y})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/rnn/rnn-bptt-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\nabla_{h_\\tau} L = V^{\\top} \\nabla_{O_{\\tau}} L_{\\tau} $$\n",
    "$$ \\nabla_{h_t} L = \\Big( \\frac{\\partial h_{t+1}}{\\partial h_t} \\Big)^{\\top} (\\nabla_{h_{t+1}} L) + \\Big(\\frac{\\partial O_t}{\\partial h_t}\\Big)^{\\top} \\nabla_{O_{t}} L $$\n",
    "\n",
    "$$ \\frac{\\partial h_{t+1}}{\\partial h_t} = W^{\\top} diag(\\phi'(h_{t+1}))$$\n",
    "$$ \\frac{\\partial h_{t}}{\\partial h_k} = \\prod_{i=k+1}^t W^{\\top} diag(\\phi'(h_{i-1}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### RNN challenges\n",
    "\n",
    "- Long term dependencies (Hochreiter 1991 Bengio 1994)\n",
    "- Vanishing Gradient\n",
    "- Exploding Gradient\n",
    "- Jacobian terms multiply many time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(modelling a sequence)\n",
    "Explain where the neurons are\n",
    "\n",
    "(Predicting the next element)\n",
    "(Sequence to vector (class) output)\n",
    "(Sequence to sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sequence to sequence mapping\n",
    "- Sequence of symbols come in as input\n",
    "- Sequence of symbols come in as output\n",
    "\n",
    "- The goal of the models it to map one sequence to another\n",
    "\n",
    "- Fixed alphabet\n",
    "- Define the problem as classification\n",
    "- Output is energies + softmax\n",
    "- Loss is cross entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Computing the gradient\n",
    "Backpropagation through time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computing the gradient through a recurrent neural network is straightforward.\n",
    "One simply applies the generalized back-propagation algorithm to the unrolled computational graph. \n",
    "\n",
    "No specialized algorithms are necessary.\n",
    "Gradients obtained by back-propagation may then be used with any general-purposegradient-based techniques to train an RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The gradient computation involvesperforming a forward propagation pass moving left to right through our illustrationof the unrolled graph in ﬁgure 10.3, followed by a backward propagation passmoving right to left through the graph. The runtime isO(τ) and cannot be reducedby parallelization because the forward propagation graph is inherently sequential;each time step may only be computed after the previous one. States computedin the forward pass must be stored until they are reused during the backwardpass, so the memory cost is alsoO(τ). The back-propagation algorithm appliedto the unrolled graph withO(τ) cost is calledback-propagation through timeor BPTT and is discussed further in section 10.2.2. The network with recurrencebetween hidden units is thus very powerful but also expensive to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing gradient\n",
    "sum goes over t\n",
    "same jacobian is multiplied many times in the chain rule\n",
    "if the gradient is less than one is vanishes\n",
    "if its larger than one it explodes\n",
    "(different from vanishing gradient in feed forward networks, you can normilize there, here same parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gating\n",
    "\n",
    "Protect the state of the RNN\n",
    "\n",
    "Rather than updating the state with each datapoint\n",
    "- Learn when to update, given the input and the previous hidden state\n",
    "- What to update given the input and the previous state\n",
    "\n",
    "- Even more so, what to remove (forget)\n",
    "\n",
    "- What to add into the memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Long short term memory\n",
    "![LSTM](images/rnn/lstm-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forget gate \n",
    "\n",
    "Long short term memory\n",
    "![LSTM](images/rnn/lstm-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Add gate\n",
    "\n",
    "![LSTM](images/rnn/lstm-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output gate\n",
    "Long short term memory\n",
    "![LSTM](images/rnn/lstm-01.png)\n",
    "\n",
    "- what we are outputing based on the cell content\n",
    "- filtered by the output gate \n",
    "- sigmod of the hidden state and the input\n",
    "\n",
    "the output is propagate to the next step as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Stack the LSTMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Sequence Prediction\n",
    "Sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Seq2Seq"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
